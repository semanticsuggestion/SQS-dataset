# SQS-dataset
**Semantic Query Suggestion Dataset**

Corpus-Based Semantic Query Suggestion through Factor Graphs


## CORPUS description 
The corpus-Based query suggestion model has been evaluated by indexing
the extended abstracts provided as RDF triples from DBpedia, 
representing full abstracts of english Wikipedia articles, usually the first section.

The dataset is available at the following url
http://data.dws.informatik.uni-mannheim.de/dbpedia/2014/en/long_abstracts_en.nt.bz2

RDF entry example:
- - -
```
<http://dbpedia.org/resource/Academy_Awards> 
<http://dbpedia.org/ontology/abstract> 
"The Academy Awards, commonly known as The Oscars, is an annual American awards ceremony honoring 
achievements in the film industry. Winners are awarded the statuette, officially the Academy Award 
of Merit, that is much better known by its nickname Oscar. The awards, first presented in 1929 at 
the Hollywood Roosevelt Hotel, are overseen by the Academy of Motion Picture Arts and Sciences (AMPAS). 
The Oscar Academy Awards are an electoral race to the trophy to best film in any category.
The awards ceremony was first televised in 1953 and is now seen live in more than 200 countries. 
The Oscars is also the oldest entertainment awards ceremony; its equivalents, the Emmy Awards 
for television, the Tony Awards for theatre, and the Grammy Awards for music and recording, 
are modeled after the Academy Awards.The 86th Academy Awards ceremony was held on March 2, 2014, 
at the Dolby Theatre in Los Angeles."@en .
```
- - -
The whole dataset is composed of **4,636,225** article abstracts.
Only the abstract text (no title) has been indexed for each RDF entry.
Noun phrases were extracted from abstract using OpenNLP chunker (http://opennlp.apache.org/).
The chunker was trained on conll2000 shared task dataset (the trained model is available here http://opennlp.sourceforge.net/models-1.5/en-chunker.bin). 
The set of candidate suggestions is composed by the backward n-grams extracted from each noun phrase.



## TEST QUERY description
### dbpedia_250.qry
This file contains 250 topics used to evaluate the query suggestion model.
First 50 'simple' topics have been created manually, while the remaining 200 'difficult' topics have been randomly extracted  
from the article-category relationships that belong to each article in DBpedia 
(http://data.dws.informatik.uni-mannheim.de/dbpedia/2014/en/article_categories_en.nt.bz2)

Each topic consist of a fixed left side that provides the query 'context', and a right side that is the 'target'.
The target side is the phrase that must be predicted by query suggestion model.
Each topic is provided as input to the query suggestion system.
The target has been trucated at 25%, 50%, and 75% as to simulate the different completing levels that a generic user generates during
the query formulation.

Topic examples:
```
vivaldi > baroque composer 
agile software development > extreme programming
```
The character '**>**' splits the context from the target.
From the above examples: 
'vivaldi' and 'agile software development' are the query context, 
'baroque composer' and 'extreme programming' are the phrase targets.

In the first example, 'vivaldi baro', 'vivaldi baroque c' and 'vivaldi baroque comp' are the topics with target cut-off at 25%, 50% and 75% respectively. 

In the second example, 'agile software development extre', 'agile software development extreme pr', and 'agile software development extreme program' are the topics with target cut-off at 25%, 50% and 75% respectively. 

### dbpedia_250.qrels
This file is a relevance judgement for query suggestion compliant with the TREC qrel format.
By adopting the TREC format, it is possible to use the trec_eval tool (http://trec.nist.gov/trec_eval/) to assess metrics on the top-10 suggestions.

Qrel example format:
```
vivaldi 0 baroque-composer 1
agile-software-development 0 extreme-programming 1
```

In the qrels file, the space character has been replaced with '-' in order to avoid problems raised by trec_eval tool.
The first field is the context of the topic, and it is always followed by 0. The third field is the target, and is always followed by 1, since only the 
right target has been reported.

A suggestion generated by the suggestion method is relevant if contains at least the whole target side of the topic.

For example:

'baroque composer violinist' and 'baroque composer' are both relevant suggestions for the first example;
'extreme programming pattern' and 'extreme programming' are relevant suggestion for the second example.



